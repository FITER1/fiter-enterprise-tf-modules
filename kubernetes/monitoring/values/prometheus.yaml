global:
    pspEnabled: true

prometheusOperator:
  admissionWebhooks:
    enabled: false
  tls:
    enabled: false

kubeScheduler:
  enabled: false

kubeEtcd:
  enabled: false

kubeDns:
  enabled: false

kubeApiServer:
  enabled: false

kubeProxy:
  enabled: false

kubeControllerManager:
  enabled: false

grafana:
  # adminPassword: add_grafana_password
  forceDeployDashboards: true

  persistence:
    type: pvc
    enabled: false
    storageClassName: gp3
    accessModes:
      - ReadWriteOnce
    size: 10Gi
    # annotations: {}
    finalizers:
      - kubernetes.io/pvc-protection


  ##
  grafana.ini:
    paths:
      data: /var/lib/grafana/
      logs: /var/log/grafana
      plugins: /var/lib/grafana/plugins
      provisioning: /etc/grafana/provisioning
    analytics:
      check_for_updates: true
    log:
      mode: console
    dataproxy:
      logging: true
      timeout: 600
      idle_conn_timeout_seconds: 600


  %{~ if INGRESSENABLED ~}
  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: nginx
      cert-manager.io/cluster-issuer: letsencrypt-prod-issuer
    hosts:
      - ${INGRESSHOSTNAME}
    tls:
      - secretName: monitoring-tls
        hosts:
          - ${INGRESSHOSTNAME}
  %{~ endif ~}

alertmanager:
  config:
    global:
      resolve_timeout: 5m
    route:
      group_by: ['job']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      receiver: 'null' # change back to slack
      routes:
      - match:
          alertname: Watchdog
        receiver: 'null'
    # This inhibt rule is a hack from: https://stackoverflow.com/questions/54806336/how-to-silence-prometheus-alertmanager-using-config-files/54814033#54814033
    inhibit_rules:
      - target_match_re:
           alertname: '.+Overcommit'
        source_match:
           alertname: 'Watchdog'
        equal: ['prometheus']
    receivers:
    - name: 'null'
    %{~ if SLACK_ENABLED ~}
    - name: 'slack'
      slack_configs:
      - api_url: '${SLACK_HOOK_URL}'
        send_resolved: true
        channel: '#${SLACK_CHANNEL}'
        title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] Monitoring Event Notification'
        text: |-
          {{ range .Alerts }}
            *Alert:* {{ .Labels.alertname }} - `{{ .Labels.severity }}`
            *Description:* {{ .Annotations.message }}
            *Graph:* <{{ .GeneratorURL }}|:chart_with_upwards_trend:> *Runbook:* <{{ .Annotations.runbook_url }}|:spiral_note_pad:>
            *Details:*
            {{ range .Labels.SortedPairs }} â€¢ *{{ .Name }}:* `{{ .Value }}`
            {{ end }}
          {{ end }}
    %{~ endif ~}

prometheus:
  prometheusSpec:
    retention: 180d
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: gp3
          resources:
            requests:
              storage: 100Gi

